20250522面试记录

本来约好了今天视频面试

昨天说面试官出差,结果给了个牛客网,自己考试,逆天

妈的,死刑

考试地址：https://hr.nowcoder.com/v1/s/xxxxx，...，如未收到邮件，可关注牛客招聘助手随时查看。

哎,试试能不能过,不行就跑路.

---

1. 请简要解释为什么transformer中有mha?对比单一注意力有哪些能力提升,是否存在冗余?
2. 如何理解agent和agentic ai的区别?说明其适用的场景和优缺点
3. 假设全参数微调一个6.5B参数的llm,adam优化器,batch_size=4,fp16情况下,1.估算显存大小. 2.怎么在一个40G显卡运行呢?
4. 简述一下opanai deepresearch和manus怎么工作的
5. 微调llm模型,过拟合的信号有哪些?采取怎么策略缓解
    ```
    过拟合信号:
    - 训练集损失显著低于验证集损失
    - 验证集性能(准确率/困惑度)停滞或下降
    - 模型对训练数据过度敏感,生成重复或不泛化输出
    - 测试集上泛化能力差,错误率高

    缓解策略:
    - 数据增强: 扩充多样化训练数据,引入噪声
    - 正则化: 使用Dropout、L2正则化或权重衰减
    - 简化模型: 减少层数或参数量,避免过度复杂
    - 早停: 监控验证集损失,提前终止训练
    - 交叉验证: 使用k折交叉验证评估泛化能力
    - 增加验证频率: 更频繁检查验证集性能
    ```
6. 怎么解决llm幻觉问题?dpo和rlhf怎么改善幻觉?

---

- 还给了3个算法题目
    - 求斐波那契数列第n个数
    - 给定一个字符串,把其中所有用空格隔开的单词反转,并且保留原来的空格和单词顺序(返回str,字符串只有小写英文和空格)
    - 给定长度为n的可重复数组,找出其中不去重的最小的k个数
